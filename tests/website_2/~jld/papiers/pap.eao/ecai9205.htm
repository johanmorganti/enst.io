<HTML><HEAD>
<!-- This document was created from RTF source by rtftohtml version 3.0.1 -->
<TITLE>Model-Based Surprise and Explanation: a way to negotiate concepts - Conclusion: a way to negotiate conceptual knowledge</TITLE></HEAD>
<BODY BACKGROUND="fond.gif" TEXT=#1809BB>
<A HREF="ecai9204.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/leftg.gif" ALT="<< " border=0></A>
 <A HREF="ecai9206.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/rightg.gif" ALT="" border=0></A>
 <A HREF="ecai92.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/topg.gif" ALT="Title " border=0></A>
<hr size=4>
<H1>
Conclusion: a way to negotiate conceptual knowledge</H1>
<b></b><p>
<b></b>Logical relevance, as it can be described in spontaneous explanations
produced during natural conversations, seems to be a desirable characteristic
of explanations that may be given by artificial systems. Model-based surprise,
when it can be recognized with a good probability, either by the user (as is
needed in SAVANT3) or by the system (e.g. by a help system), can lead to
logically relevant explanations. Alternating surprises and explanations should
be an interesting way through which KBS could negotiate conceptual knowledge
(which corresponds to the structures mentioned above, as opposed to procedural
knowledge), even during task-oriented interactions. SAVANT3 relies on such a
negotiation. <p>
Every KBS user has expectations, and (s)he needs a conceptual explanation when
the situation does not match them. We tried here to indicate a possible way to
give logically relevant explanations by recognizing and invalidating user's
expectations.<p>
<p>
<P><hr size=4>
<A HREF="ecai9204.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/leftg.gif" ALT="<< " border=0></A>
 <A HREF="ecai9206.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/rightg.gif" ALT="" border=0></A>
 <A HREF="ecai92.htm"><IMG SRC="/~jld/rtf2html/r2hwin/docs/images/topg.gif" ALT="Title " border=0></A>
</body></html>